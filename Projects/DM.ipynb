{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptual decision making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data generation\n",
    "$u(t)= \\bigg\\{ \\begin{array}{ll} \\bar{u} + \\xi (t) & \\text{if } 5 \\leq t \\leq 45 \\\\  \\xi (t) & otherwise \\end{array}$\n",
    "\n",
    "$\\bar{u}$ stimulus strength, drawn from a uniformormly from $\\pm \\frac{3.2}{100} \\{1,2,4,8,16\\}$ \n",
    "\n",
    "$\\xi (t)$ is background noise, drawn from a normal distribution with mean 0 and standard deviation 0.03. \n",
    "\n",
    "resample for each trial. noise resampled for each time step. \n",
    "\n",
    "target $y$ is $sgn(\\bar{u})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy.linalg as la\n",
    "# #%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below snippit taken from PyTorch quickstart tutorial\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionDataset(Dataset):\n",
    "    def __init__(self, n_trials, n_time_step=75):   \n",
    "        \"\"\"\n",
    "        Generate perceptual decision-making data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_trials : int\n",
    "            Number of trials.\n",
    "        n_time_step : int (Default: 75)\n",
    "            Number of time steps.\n",
    "        Returns\n",
    "        -------\n",
    "        u : array, shape (n_trials,n_time_step)\n",
    "            input \n",
    "        y : array, shape (n_trials,n_time_step)\n",
    "            output \n",
    "        \"\"\"\n",
    "        strength_choices = (3.2/ 100)  * np.array([1,2,4,8,16, -1,-2,-4,-8,-16])\n",
    "        n_time_step = 75\n",
    "        time_step= 20 #ms\n",
    "\n",
    "        u = np.zeros([n_trials,n_time_step])\n",
    "        y = np.zeros([n_trials,n_time_step])\n",
    "\n",
    "        for trial in range(n_trials):\n",
    "            strength = np.random.choice(strength_choices)\n",
    "\n",
    "            for t in range(0,n_time_step):\n",
    "                if t>=5 and t<=45:\n",
    "                    #noise with std 0.03\n",
    "                    u[trial,t] = strength + np.random.normal(0,0.03)\n",
    "                else:\n",
    "                    u[trial, t] = np.random.normal(0,0.03)\n",
    "\n",
    "                y[trial, t] = np.sign(strength)\n",
    "        \n",
    "        self.u = torch.tensor(u, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.n_trials = n_trials\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_trials\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.u[idx,:], self.y[idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_data = DecisionDataset(1000)\n",
    "d_dataloader = DataLoader(d_data, batch_size=32)\n",
    "\n",
    "u_arr, y_arr = next(iter(d_dataloader))\n",
    "\n",
    "plt.figure(figsize=(18,12))\n",
    "plt.suptitle('Perceptual Decision-Making Data samples', fontsize=20)\n",
    "for idx in range(4):\n",
    "    plt.subplot(2,2,idx+1)\n",
    "    plt.plot(u_arr[idx,:], label='trial # {} input'.format(idx))\n",
    "    plt.plot(y_arr[idx,:], label='trial # {} output'.format(idx))\n",
    "    plt.xlabel('time (ms)', fontsize=16)\n",
    "    #dt = 20msb\n",
    "    plt.xticks(np.arange(0, 75, step=5), np.arange(0, 1500, step=100))\n",
    "    plt.ylabel('input/output', fontsize=16)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Recurrent neural network\n",
    "one dimensional input and output, \n",
    "\n",
    "N units in the hidden layer, \n",
    "\n",
    "left and right connectivity vector $m, n$ trainable parameters, \n",
    "\n",
    "fixed input and output weights $I, W$. \n",
    "\n",
    "trainable and fixed weights are drawn from standard normal distribution. \n",
    "\n",
    "$\\tau \\frac{dx_i}{dt} = -x_i + \\sum_{j=1}^N J_{ij} \\phi(x_j) + I_i u(t)$ \n",
    "\n",
    "$\\phi(x) = \\tanh$ \n",
    "\n",
    "$\\tau = 100 ms$ \n",
    " \n",
    "$\\Delta t = 20 ms$ \n",
    "\n",
    "$J = \\frac{1}{N} mn^T$ \n",
    "\n",
    "Using forward Euler method to solve the differential equation. \n",
    "\n",
    "$x_i(t+ \\Delta t) = x_i(t) + \\frac{1}{\\tau}  \\Delta t  \\bigg( -x_i(t) + \\sum_{j=1}^N J_{ij} \\phi(x_j(t)) + I_i u(t) \\bigg)$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, network_size=128):\n",
    "        \n",
    "        super(RNN, self).__init__()\n",
    "        self.network_size = network_size\n",
    "        \n",
    "        # Weight initialization\n",
    "        #unit rank rnn weight matrix J=mn^T/n\n",
    "        self.m = nn.Parameter(torch.Tensor(self.network_size))\n",
    "        self.n = nn.Parameter(torch.Tensor(self.network_size))\n",
    "\n",
    "        self.wi = torch.Tensor(self.network_size)\n",
    "        self.w = torch.Tensor(self.network_size)\n",
    "        \n",
    "                # Parameters for weight update formula\n",
    "        self.tau = 100 #ms\n",
    "        self.dt = 20 #ms\n",
    "\n",
    "        # Activation function\n",
    "        self.activation = nn.Tanh()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.m.normal_(std=1)\n",
    "            self.n.normal_(std=1)\n",
    "            self.wi.normal_(std=1)\n",
    "            #orthogonalize m and n gram schmidt\n",
    "            self.wi =    self.wi - torch.dot(self.m, self.wi) * self.m / torch.dot(self.m, self.m)\n",
    "            self.wi =    self.wi / torch.norm(self.wi)\n",
    "            \n",
    "            self.w.normal_(std=4)\n",
    "            \n",
    "\n",
    "    def forward(self, u):\n",
    "        x = torch.randn(u.size(0), self.network_size)\n",
    "        z = torch.zeros(u.shape)\n",
    "        #unit rank rnn weight matrix J=mn^T/n\n",
    "        J = torch.matmul(self.m[:,None], self.n[None,:]) / self.network_size\n",
    "        \n",
    "        for i in range(u.size(1)):\n",
    "            delta_x = (\n",
    "                -x \n",
    "                + torch.matmul(self.activation(x), J) \n",
    "                + torch.matmul(u[:,i,None], self.wi[None,:])\n",
    "            ) * (self.dt / self.tau)\n",
    "            \n",
    "            x = x + delta_x\n",
    "            \n",
    "            output = torch.matmul(self.activation(x), self.w) / self.network_size            \n",
    "            z[:, i] = output    \n",
    "            \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rnn = RNN(128)\n",
    "n=test_rnn.n\n",
    "m=test_rnn.m\n",
    "wi=test_rnn.wi\n",
    "w=test_rnn.w\n",
    "print(\"inner product of m and n:\",torch.dot(m,wi))\n",
    "#rank of J=1/nmn.T\n",
    "J=torch.matmul(m[:,None], n[None,:]) / test_rnn.network_size\n",
    "J=J.detach().numpy()\n",
    "print('rank of J:',la.matrix_rank(J,tol=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training\n",
    "train a network of size $N=128$. batch size 32 trals. and specific lost function is defined as the mean squared error of last $T=15$ time step of each trial:\n",
    "\n",
    "$loss = \\frac{1}{32 * 15} \\sum_{i=1}^{32} \\sum_{t=45}^{60} (z_i(t) - y_i(t))^2$ \n",
    "\n",
    "learning rate $0.05$ , Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function slightly modified from PyTorch quickstart tutorial\n",
    "def train(dataloader, model, loss_fn, optimizer, T=15):\n",
    "    size = len(dataloader.dataset)\n",
    "    optimizer.zero_grad()\n",
    "    model.train(True)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        # print(\"pred shape: \", pred.shape)\n",
    "        loss = loss_fn(pred[:,-T:], y[:,-T:])\n",
    "\n",
    "        # print(pred[0, :])\n",
    "        # print(pred[0, -T:])\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting sanity check\n",
    "d_dataset = DecisionDataset(32000)\n",
    "train_dataloader = DataLoader(d_dataset, batch_size=32)\n",
    "\n",
    "learning_rate = 5e-3\n",
    "T=15\n",
    "model = RNN(128)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for t in range(1):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer, T=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(128)\n",
    "n=model.n\n",
    "m=model.m\n",
    "wi=model.wi\n",
    "w=model.w\n",
    "print(\"inner product of m and n:\",torch.dot(m,wi))\n",
    "#rank of J=1/nmn.T\n",
    "J=torch.matmul(m[:,None], n[None,:]) / model.network_size\n",
    "J=J.detach().numpy()\n",
    "print('rank of J:',la.matrix_rank(J,tol=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "u_arr, y_arr = next(iter(d_dataloader))\n",
    "\n",
    "plt.figure(figsize=(18,12))\n",
    "plt.suptitle('Perceptual Decision-Making Data samples', fontsize=20)\n",
    "for idx in range(4):\n",
    "    plt.subplot(2,2,idx+1)\n",
    "    plt.plot(u_arr[idx,:], label='trial # {} input'.format(idx))\n",
    "    plt.plot(y_arr[idx,:], label='trial # {} output'.format(idx))\n",
    "    plt.plot(model(u_arr[idx,:].unsqueeze(0)).detach().numpy().squeeze(), label='trial # {} model output'.format(idx))\n",
    "    plt.xlabel('time (ms)', fontsize=16)\n",
    "    #dt = 20msb\n",
    "    # plt.xticks(np.arange(0, 75, step=5), np.arange(0, 1500, step=100))\n",
    "    plt.ylabel('input/output', fontsize=16)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=model.m.detach().numpy()\n",
    "n=model.n.detach().numpy()\n",
    "I=model.I.detach().numpy()\n",
    "w=model.w.detach().numpy()\n",
    "\n",
    "#check if n is orthogonal to m\n",
    "print(np.dot(m,n))\n",
    "\n",
    "net=np.stack([m,n,I,w], axis=0)\n",
    "cov=np.cov(net)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(cov)\n",
    "plt.colorbar()\n",
    "plt.title('Covariance of network weights', fontsize=20)\n",
    "plt.xticks(np.arange(0, 4, step=1), ['m', 'n', 'I', 'w'], fontsize=16)\n",
    "plt.yticks(np.arange(0, 4, step=1), ['m', 'n', 'I', 'w'], fontsize=16)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18,12))\n",
    "plt.suptitle('two-dimensional projections', fontsize=20)\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(n, I)\n",
    "plt.xlabel('n', fontsize=16)\n",
    "plt.ylabel('I', fontsize=16)\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(m, n)\n",
    "plt.xlabel('m', fontsize=16)\n",
    "plt.ylabel('n', fontsize=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "  <img style=\"float: left;\"  width=\"140\" src=\" data:image/png;base64,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\">\n",
    "</div>\n",
    " \n",
    "<h1 id=\"course-title-heading\">\n",
    "    <div style=\"text-align: right\">\n",
    "        Models of Higher Brain Functions\n",
    "        <br>Computer Course\n",
    "        <br>\n",
    "    </div>\n",
    "</h1>\n",
    "    \n",
    "---\n",
    "<div style=\"text-align: left; float: left\">\n",
    "    Lecturer: Prof. Dr. Henning Sprekeler\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: right\">\n",
    "    Assistant: Jarek Liesen\n",
    "    <br>(jarek@bccn-berlin.de)\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General exercise instructions\n",
    "These exercises should be completed entirely in this Jupyter Notebook (comprising source code, discussion and interpretation). Submission should be done through the Moodle interface and should consist only of this notebook (**a single `.ipynb` file**). This Jupyter Notebook was provided inside a `.zip` file, alongside additional files. Do not change the relative paths of these files when working on the assignment (meaning that e.g. `./helper.py` should always be in the same directory as this notebook).\n",
    "\n",
    "Submission deadline is the start of the next lectue (**10:15 am on Fridays**).\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Some of the exercises will be automatically graded. Make sure that you:\n",
    "1. Fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\"\n",
    "2. Remove all `raise NotImplementedError` lines once you inserted your solution\n",
    "3. Don't use variable names starting with underscore (e.g. `_myvar`) in your code, which could interfere with the automatic grading system.\n",
    "\n",
    "Before you start, please fill in below your names and the name of your group as shown on Moodle. Example:\n",
    "```\n",
    "NAMES = [\"Martina Musterfrau\", \"John Smith\"]\n",
    "GROUP = \"A\"\n",
    "```\n",
    "\n",
    "If you have any questions about the exercises, please ask them **on the Moodle forum** of the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMES = [\"\", \"\"]\n",
    "GROUP = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are a few tests to make sure that your installed Python software is not too old\n",
    "import sys\n",
    "assert sys.version_info.major >= 3, \"Your Python version is too old, please update it.\"\n",
    "\n",
    "import IPython\n",
    "assert IPython.version_info[0] >= 3, \"Your IPython version is too old, please update it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ab7d2b2a65bcbe1183ba63abd9047d4",
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Week 7: Reinforcement Learning I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2edfca0803fe53c7ea4fc108acaba177",
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Necessary imports for this exercise, you can't modify these\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import functions defined in the ./helpers.py file\n",
    "from helpers import assert_var_defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add your additional package imports here\n",
    "\n",
    "# Create plots inline in the Jupyter notebook\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a0296ca8733adff5f2f97ffdc3959f1",
     "grade": false,
     "grade_id": "1-intro",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1: The 10-armed bandit\n",
    "\n",
    "In this exercise we will test multiple policies that are supposed to learn the optimal strategy for a 10-armed bandit. A 10-armed bandit is a machine consisting of 10 levers and a reward distribution device, e.g., a chocolate dispenser. Each lever has a fixed probability of generating a reward of 1 (piece of chocolate) when operated. At the beginning, the \"agent\" does not know anything about the machine, but while activating different levers,\n",
    "she will learn more and more about the reward characteristics. While one aim is to get a good estimate of the reward probabilities by playing around (exploration), the agent concurrently intends to maximize the overall chocolate output (exploitation). The tricky question is: What is a good strategy that balances exploration and exploitation? Which levers should be activated given the reward history?\n",
    "\n",
    "\n",
    "All strategies in this exercise rely on a common idea: The agent assigns a so-called $Q$-value $Q(a_{i}) = Q_{i}$ to each of the possible actions $a_{i}$ (press lever i). Ideally, the $Q$-values\n",
    "mirror the expected reward associated with each action. After pressing a lever, the action values are updated depending on whether a reward was received ($R = 1$) or not ($R = 0$):\n",
    "\n",
    "$$\n",
    "\\Delta Q_{i} = \\eta [R-Q_{i}]\n",
    "$$\n",
    "\n",
    "The parameter $\\eta$ represents the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "80700613ee19a4354a46b87120e87ee4",
     "grade": false,
     "grade_id": "1-1-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1 .1) Generate reward probabilities (0 points)\n",
    "\n",
    "Generate an array `p` of 10 random lever reward probabilities $p_{i} \\in [0,0.9]$ and **keep it fixed for the entire exercise sheet**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec31040721d341e762d35fbc734fb34c",
     "grade": false,
     "grade_id": "1-1-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd7dcf97552ff40e510435b3a9b11a52",
     "grade": true,
     "grade_id": "1-1-tests",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Test that variable `p` is defined \"\"\"\n",
    "\n",
    "assert_var_defined(\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a7647450561e4da0d02a5ec2018db1a",
     "grade": false,
     "grade_id": "1-2-a-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2) Implemente an N-armed bandit (0.5 points)\n",
    "\n",
    "Write a function `generate_reward` that will behave as an N-armed bandit (given lever numbers corresponding to indices into `p`, it returns rewards of 1 with a probability $p_{i}$ , otherwise zeros).\n",
    "Confirm that your bandit works: Activate each lever 10000 times and compare the mean reward for each lever with its reward probability – they should be nearly identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1e11dc78bbd202bf0f88ef26d750e81",
     "grade": false,
     "grade_id": "1-2-a-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a04adc700444753e8ff6e4198cdd492",
     "grade": true,
     "grade_id": "1-2-a-tests",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Test that function `generate_reward` is defined \"\"\"\n",
    "\n",
    "assert_var_defined(\"generate_reward\", func=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3e821e17d4ceb203d2b2c07d0fe1a7c",
     "grade": false,
     "grade_id": "1-2-b-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.2 b) Test your reward function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "644b9c3261a2b37a5d2a947090fca5dc",
     "grade": true,
     "grade_id": "1-2-b-answer",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9ba46beff90e3ae68942fa8a19b0ede",
     "grade": false,
     "grade_id": "1-3-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3) Device some method of storing and updating the $Q$-values (1 point)\n",
    "\n",
    "Devise some method of storing and updating the $Q_{i}$ value associated with the action of pressing lever i (take $\\eta$ = 0.01). Q should be initialized with zeros, since the agent is pessimistic and initially associates zero value with each action.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb04c4482d623b90dada9b3e8699dbba",
     "grade": true,
     "grade_id": "1-3-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "42c7407008cc68bd726113b6e869c2aa",
     "grade": false,
     "grade_id": "1-4-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.4) Implement the *$\\epsilon$-greedy* policy (1 point)\n",
    "\n",
    "We will first implement the $\\epsilon$-greedy policy: The agent will with probability $1 − \\epsilon$ press the lever which has the maximum associated Q-value (if there are several with that value, press them all), otherwise press a random lever. The agent starts by pressing all levers (since they all have the same Q-value initially), it updates the Q-values and then applies the described strategy iteratively. \n",
    "\n",
    "Write a function `eps_greedy` that implements this strategy. \n",
    "\n",
    "The function should accept as input the current $Q$ and should return the lever index (or indices)\n",
    "that are to be pressed, the Q-value of the chosen lever, as well as the largest Q-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56f2ef5450415b50fdf61eb442fb7cc9",
     "grade": true,
     "grade_id": "1-4-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "325906945cf7390c5ac84a0ca44d77e7",
     "grade": false,
     "grade_id": "1-5-a-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.5) Test the pure-greedy algorithm (2 points)\n",
    "\n",
    "#### 1.5 a) Implement the algorithm (1 point)\n",
    "First we'll test the pure-greedy algorithm. Write a function that sets $\\epsilon = 0$ and runns 1000 iterations of the algorithm: \n",
    "  1. Choose the next lever(s) (`eps_greedy`).\n",
    "  2. Activate the chosen levers (`generate_reward`).\n",
    "  3. Update the Q-values according to the received rewards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f902a2aac3cf9cd646624a1ad093f3de",
     "grade": true,
     "grade_id": "1-5-a-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "15147692b0a9e43cd9f449e9e623775a",
     "grade": false,
     "grade_id": "1-5-b-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.5 b) Plot the estimated expecte rewards for 20 \"lives\" (0.5 points)\n",
    "\n",
    "Plot the estimated expected reward (the Q-value of the current lever) against the trial number (each lever press constitutes one trial).\n",
    "\n",
    "Repeat the test 20 times and draw the resulting curves into a single plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62ac714d1c832c98be68f74ee622fef7",
     "grade": true,
     "grade_id": "1-5-b-answer",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e583f159a43f89792f4e45092c7385d",
     "grade": false,
     "grade_id": "1-5-c-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.5 c) Discuss your results (0.5 points)\n",
    "\n",
    "Does the agent consistently identify the levers with the largest reward probabilities? Explain which levers the agent pulls in the first trials and how this resulst in the behavior you plotted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06719b524fc36e6ec2361cc308e14081",
     "grade": true,
     "grade_id": "1-5-c-answer",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7945166d3111a7f716c2a53e0bfd7246",
     "grade": false,
     "grade_id": "1-6-a-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.6) Test the $\\epsilon$-greedy algorithm\n",
    "\n",
    "#### 1.6 a) Simulate the algorithm for different $\\epsilon$ values (2 points)\n",
    "\n",
    "Run 100 repetitions (\"lives\") of the $\\epsilon$-greedy strategy (with four different $\\epsilon$-values 0.0, 0.01, 0.1 and 0.5) at 1000 iterations each and store the expected reward in each trial. \n",
    "\n",
    "\n",
    "Plot the average of the expected reward, and the average largest Q-value across lives against the trial number. Include a line in the plot that runs parallel to the x-axis and represents the maximum expected reward (the maximum reward probability). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f149aec530f7864c70f0143d45468b3",
     "grade": true,
     "grade_id": "1-6-a-answer",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27f55857363d813c35ec480ddfde63f3",
     "grade": false,
     "grade_id": "1-6-b-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.6b) Discuss your results (2 points)\n",
    "\n",
    "Why do the expected reward and largest Q-value curves look the way they do for the four cases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a592a151cd42c452f9d81c8bfbd4566b",
     "grade": true,
     "grade_id": "1-6-b-answer",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d90369c2d96fa65d8e3541c330ff9bc8",
     "grade": false,
     "grade_id": "1-7-intro",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.7 Implement a *SoftMax* policy\n",
    "\n",
    "Finally, we program a *SoftMax* policy: The agent presses the levers with probabilities that depend on the Q-values:\n",
    "\n",
    "$$\n",
    "P_{i} = \\frac{\\exp(\\beta Q_i)}{\\sum_j\\exp(\\beta Q_{j})}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32861f7d67b6cac8efd7bc633376219e",
     "grade": false,
     "grade_id": "1-7-a-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.7a) Write a function that implements the policy (1 point)\n",
    "\n",
    "Write a function `softmax` that implements this strategy. The function/method should accept as input the current Q and output the lever index(it will always be a single lever index!) that is to be pressed, as well as the maximum Q-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba0faaa885587a61b8062f7ac3fc68e3",
     "grade": true,
     "grade_id": "1-7-a-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7e1026f45c1c0c33a4f5f4fdeb33d35",
     "grade": false,
     "grade_id": "1-7-b-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.7 b) Simulate the *SoftMax* strategy for different $\\beta$ (1.5 points)\n",
    "\n",
    "Test this function by running 100 lives with 5000 iterations each and store the expected reward and maximum Q-value in each trial. \n",
    "\n",
    "Draw the same curves as in task 1.6 for different values of  $\\beta$  = 1, 5, 15, 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da68e7f834ddbc478ee3f5a068ff0380",
     "grade": true,
     "grade_id": "1-7-b-answer",
     "locked": false,
     "points": 1.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "35c56e1f1e1d638bf17c3b2a95e9da9a",
     "grade": false,
     "grade_id": "1-7-c-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.7c) Discuss your results (1 point)\n",
    "\n",
    "Do the results of SoftMax show any improvements compared to the $\\epsilon$-greedy policies? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "992dd4b17f85839dbbc85b6a75285d87",
     "grade": true,
     "grade_id": "1-7-c-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "88f113e9d662daf8886f99cba1eb8471",
     "grade": false,
     "grade_id": "1-7-d-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.7 d) Explain the $\\beta$-parameter (1 point)\n",
    "\n",
    "How does the parameter $\\beta$ relate to the exploration/exploitation-balance? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "457a8835ce3780b870e5e5f5ce188892",
     "grade": true,
     "grade_id": "1-7-d-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f7b677ca2969b637d3e8c1a904479ec9",
     "grade": false,
     "grade_id": "1-7-e-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.7 e) Explain your results (1 points)\n",
    "\n",
    "And once again explain why for each $\\beta$ the two curves (expected reward & largest Q-value) look the way they do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c2c92d21606f58d85e32072545ea5fb7",
     "grade": true,
     "grade_id": "1-7-e-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "62483f1aba4a9fea7005fd796e4d77da",
     "grade": false,
     "grade_id": "1-8-a-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.8) Add a catastrophic action\n",
    "\n",
    "#### 1.8 a) Modify your bandit and test your policies (1 point)\n",
    "Modify the 10-armed bandit so that operating the last lever always gives a reward of -5000 (the agent is punished and has to return 5000 pieces of chocolate). \n",
    "\n",
    "Test both the epsilon-greedy and SoftMax policies on this modified bandit (use $\\epsilon$ = 0.1, $\\beta$ = 15) by running 500 lives with 1000 iterations each and plot the same curve as in task 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a42b3a09c3fb94fac6d795806eb70c57",
     "grade": true,
     "grade_id": "1-8-a-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd7e1fae7edc78177c7ff070a58cc5fe",
     "grade": false,
     "grade_id": "1-8-b-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.8 b) Discuss your results (1 point)\n",
    "\n",
    "Do you observe a difference? Give an intuition for the result! (After this task ditch the punishment and return to the original bandit.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c13718d5270e72d7d4012ad1e44efb87",
     "grade": true,
     "grade_id": "1-8-b-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e8c6bf47d19096f9844d2883f8433eb9",
     "grade": false,
     "grade_id": "1-9-a-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.9) Implement a *modified SoftMax* policy with dynamic $\\beta$\n",
    "\n",
    "#### 1.9 a) Implemente the new policy (1 point)\n",
    "\n",
    "Implement a modified SoftMax policy, where the parameter $\\beta$ increases linearly with the number of iterations i starting at a value of 1:\n",
    "\n",
    "$$\n",
    "\\beta(i) = 1 + \\frac{i}{b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "edf615b14dfc334d9f77734184e3bb68",
     "grade": true,
     "grade_id": "1-9-a-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad9b07126f6208229787816811021d8c",
     "grade": false,
     "grade_id": "1-9-b-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.9 b) Test the policy for different $\\beta$-slopes (0.5 points)\n",
    "\n",
    "Run the simulations with 5 different $\\beta$-slopes: b = 0.1, 0.4, 1.6, 6.4, 25.6. and also with the simple SoftMax ($\\beta$ = 5).\n",
    "In each simulation, run 100 lives with 2000 iterations and plot the same curves as in task 6.\n",
    "\n",
    "How are the plots with different $\\beta$-slopes different from the simple SoftMax simulation?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ba415e42da94917df644b04b98e0f02",
     "grade": true,
     "grade_id": "1-9-b-answer",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d833116c562cb6d41ab55175aad0703",
     "grade": true,
     "grade_id": "1-9-b-answer-text",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1cd9e281942b63beeeb7cbc0cf50ae46",
     "grade": false,
     "grade_id": "1-9-c-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.9 c) Plot the cumulative sum of true rewards (0.5)\n",
    "\n",
    "In a different figure, plot the cumulative sum of true rewards (the sum of rewards until the current trial, aver-\n",
    "aged over lives) against trial number.\n",
    "\n",
    "What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83a7d4096885454664164f7d8efd9381",
     "grade": true,
     "grade_id": "1-9-c-answer",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "044d4ff55a0c0d05ca1bcf43f8a4e8cb",
     "grade": true,
     "grade_id": "1-9-c-answer-text",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8b53eeb103b74c0d272bcc3f6332f1f2",
     "grade": false,
     "grade_id": "1-9-d-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.9 d) Plot the cumulative reward against $\\beta$-slope (0.5 points)\n",
    "\n",
    "Furthermore, plot the cumulative reward at the end of the lifetime (2000 iterations) against the $\\beta$-slope.\n",
    "\n",
    "Which of the five slopes generates the maximum overall reward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db730fa080a9ae03d5e0bdfa1d209f12",
     "grade": true,
     "grade_id": "1-9-d-answer",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e2463db0186c11f002f211c0ef6953a9",
     "grade": true,
     "grade_id": "1-9-d-answer-text",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2c07d1807f84d424d9f06a9b2fc41632",
     "grade": false,
     "grade_id": "1-9-e-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.9 e) Discuss the idea behind using a varying $\\beta$ (1 point)\n",
    "\n",
    "Explain the idea behind using a varying β, in particular regarding the exploration/exploitation dilemma?\n",
    "\n",
    "Can you think of a similar modification to the  $\\epsilon$-greedy policy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c84fc0fc0fbba8705b4a364fbab33c6f",
     "grade": true,
     "grade_id": "1-9-e-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "  <img style=\"float: left;\"  width=\"140\" src=\" data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA4QAAAH0BAMAAACX3f7gAAAAMFBMVEVYksju9PnC2/Grxd8AUKMAQZSEqdBQh74va6wANo3a5vJBfLcTVqAhYaYASpj////zXPJYAAApFElEQVR4Xuyd0WscRRjAtxZvwAPTpCBwL4tbsHAFryRaoAUOdALkJRRJURBKNPSgBsjQYgZYwJf2WcEIiFBMAgKn5Q6LWfAABexLCr75H8Q3le4dnHICmoZ4d7PbHFx3dmXg93u/p9/NN9/M98233j+OA/+nQkAhoBCFgEJAIaAQhYBCQGFlJwiaPgrdZS44ooVCdw0e46PQTeLgP6oodHgRuhxKURiMqKLQRQbBGD4K3YyjI2quq0Dhyyh0kJ2AzRCFKEQhClFIOuO0QhR2Xc9IURgHIzgXur8Z+ih094aNO1L3lyGVCvd3Q+qF7ofSKlV7d4mfxNIm7U9OE8/ShAgoBBQCClEIKAQUAgpRCCgEFAIKUQgoBBQCCp8NFAIKAYUoBBQCCgGF8fY2Cl1mcMnzvMa8j0JXOSsirXXUKdVQ6KjBUHvqEC9UdRS6SDfU4hjdbqHQQa601RDxAIXu0Ys8NSLcQKFzfK0M9lDoHMIkrKPQFvFsc3u2gGSmrQzE9yi0RKWg59P9tjLZQ6HlyVqtohWqFgpt0C1soM8ZlSCso9CtqeePk6uwvIFC29PtWsUG0hCFjo0J7WuRAIU2CAz8/A8VrEL7Q7UKi6SxSFC2U3FCYXGjXi+oBK4VflHYbwsDS7UK9sLi8pm4bMbRGTsCyEgLnJl9xkho7BR9UTgXFDgzO15XI8JTFJty2AzzXhe9sh6G0U2q9nlE0vz7n8qROCLcrKHQEoNiPx9xdrUTaR1GpRodbFbLhQVOXB6ca6yWGvO0Ajv9pWt/loZ8y1R2nJ96TvtTpVKxujKAx2koBBQCCgGFKAQUAgoBhSgEFM46feeGwnh31fNKa862t6AwvhjqQ6LSZQQ4qvBipMQhXth+z2JNq7h6Fgq/jNQxul23I7C7fmfx4NFpH4WF0NVqiNizsnT6dz77Q8rFez/WUFgE59u2+z17d6/LI65dbaEwf2ItxvBsvF55cUUes/QmCvOn37b9DPD+lhxybQaFuXNBGHi3M4fRh3KML3wU5s26MGlnVfjqihxj6WMU5kwslEnW17jxL9LgExTmzEAkyDpc5M8tabC4gcL8T4UmGROQ16XJ8j4K82WgRYKMJ8PvpMwxksbNZrW5baZIBFJlol/Ilo+uyAS/1uy/6tlG4RiWFf6dUrj0kbUluDNhTgCHCluB9JsDmWTf9qss0yEKz9vNSG/IFJ/aivknDXvggs3qlKbnZYqrtl+Zmw8kUTgIDYNeO9t2dVemeMf6rAdzGVJsuqLG0d9mC3Y/yRS/+1a6sbpBAh+Fx/QiMcIL69kUyjQH0xYNKwsNr7R2OZ3MmLRQ+LRlqPcyhuUDmWbK3XVXdCKtO+p068St0IykKOyGyvichPVVOJ3Cl8paPUGHm62JCqsoHPJVRx0TPpc1OfpZpvhtKoW98qhosulPUhigcMQroT7624eZe87iO09RONWmta7EkPCDiQp9FI7Y9cJOJyq9nz3J+zDbocLsA/GimpHOoHAC8bmFhXkbKd5NmeLtZz7i6PKtsRhNIC2G1w4yXbB1IzWG8PQoCMekM8Xw14pM8sZUc2iFQfmUsRlyqCiAfkrh4g/TxFFPmTwYW6Ec7QthsJxSWM9S+lL+icuQSkVO3MySkA6ESlCun5TQ1FCYE/cTkXT5ramasbzUR2aKrvmisHddGizNTPNjrRKYTQRzdifionDukhbp64Ab5rHiXX8qhd7kVp6KRYMoHKw//PyQe4/WTEmPt4xkZn9SO1PD8xpVI5CKJLcSv6k0d6pNG7MdUPgvO2cUEkUQBmCiyuoilV6kkgKKfPICwohIg+aiJTikbtJLXSKwUKjrzaIeO8KiCrpVj+ogCgMJTomUiChBg6Igg3ypXmoX2Iih7kDlKqiwu9nZm9m2afbt/x5l9eA+///+uf//ZzCZNsgvrLjxKsyGYQxR2sNCgQ1LIxbG5PMo7QwWyhJpD1WoFlBYZWdIkXgb42nGQiW080KDx2w8bzneQavOijKWg8JgmHmmE0q8nzlm1+GiQatZWHsu0mmybSn9+na3wVAlKAyEXK9OnMSfMgG2A5vzMUjD00VhZQpR6DLwnR63wiZQGAidGcKSZoNl6yTGFsZPhO//8RRyghN0JNJFFhQGwRqDuBlg3+pboYvvL9BS1U1dCrHsF614SM/ygMLVHqsnX0tplGI/dz9U7b3LzRIrZtxNrMHQAlAo52/zo3cTL8+Jmvg1GVLOdd8Zjx47KNrjUsOwwklPGBTKMHgWY0IsbE2H+UFIONhTvg1+0ZGbaKmpuH74v0+FoLBKKwaJvZdXj8xmCI8B3wqXoXL6SrVqyKFwOAwKJZiZpGnOauOkxy6d8LAr/b5ACnlN7edPl+YuHnZLCACFuaSJKNrH8gcw4XPV7za+iThkaR4Pjc1n0bHDMgJA4RYag/zrm77RPCpV0OQmEQfTkbJvHTr9mxNSBkFhHiMK9/qmLiLArpRY5S4SbWJGIhuWHHHPRIJC2Synjbjq0WdEgPVJ5hWoQiWAwkIEubnmKkYyRIS/60mSiIcJCoMbA9XY5fsfOhHR7if15U3EJQsK1dDJSXG72DwoVhhP+DnXxxCP1nWgUAkFWi2KMukpIsT2M/Rby1fYp0AAKBSduiNNjGQi5qAPAfWIy35QqIZaE1G4E/X5DBHjJ5S2IR6Ry6BQDY2Ixwe2IBXTIjHtrfbKS1DYiXgcYL+bETMgp5BO7YNCZTu64nrmu07EtGcl/0ui+0ChIh4gHh0OM2u9FOphySjUEqBQEUnExWHmtpdCu8n3rcEsbcEKAIURh8KNngoTcudCbSpgAaDQEVyN/6twlqOwNQsKVXE/eIW5KHJjjygXABWpOJHWSysUT85cCVoAnAvNrEqFcynEghOgUB0b/nruvuul0PLT9Cu8QQzWa4UCQGFNDHHodxaUsudCSm2GicHdQbeZoFPBdhHmvBTeKNlg1nKHbrI/WRxzGNwZfDUK/cLouLNj+2/fkeYaTr4g+stRZkMml8TFJIqngzcIXXukJfw2m5rdEXj0UtrAOsFp422384+ciRjEJJaxh65tgMIAPww7mAhiEqn3MHB+Rdr487iVztxj9uxD7ycm3i5UH4KgMKf/raHeS4RY44yAVb0GcZCeZgRUDw1JRCAolGkkaD/ZO+PQqqo4jluVsUxwBjXQ8ZQQAqIZkbUQB/UEBjCG7ojX5sUsrZH0IHDDFsoaEyaGw3m3XbZdKIEizSGBMqNCyeoNCyKqRv9FB7wxDnvvwXNcAVIcnb3d++45u2+d/Qbfz7/v/ffh3HN+v/P7/c6xUCWwVi1wcdITJbi/mBAAhdOhM+mQXCyKwJDNDQsLk6E/Wieg0ARVsnwmcuzILU/rQJo7Ev4f9zJQaIAii++pyDOt08zWKNN8OAWFBthqhzqb9ApJ/S4poGiJKKwJKDRA7sE5Dv3wEeS8rbEVVpX5k9cAhQbIH2Wz+2ET+07GhMoyxEEp4AlHROPvhEIT5Fc3srshvt9yXBosiQwV8xJy46IcLAOFRtjS+S1jLb/vjy6p96Ll1MliU0eUg/dDoSE+K/8aS4Gp3IyL8rAGKFx62uz4zrSiI8rjX4XCJSNWER+QAuptEcMQFBKg3o5bhIEv4vAzULj0FPy4YGHGE3Hw01BIgE+deVpG61R3GZIhKKTAoVKHTkYKyHMh6H9JoTA4PMchd6+ErjJwJpUKiRI86triHtbI/TojMSQDUEiC3Fu+4zDGHPf710p7FIWK1jEopMHHb35148aPl+cVoRVsocLKQCEZZAmTuhlf4p+CQspssoWSfiikTJVQMwiFhAmuCzWtKSikS8EWangDFBJEBvZq/GNQSJdaLYU/QyFdttlCgx1QSJc2oUM/FNLliNChDwrJkvtV6PAqFJqn+uzBgytWKt+OCIQWe1NQaJhg80nOXNdhP7THS8x7QhCM7aHw8R6XcXEHm7k3H1FG9mrsOig0yoasIwVY3hcxS6jo6SlsgEKTvOiWLC3u/hb3uqTQgUOhSZ5y52uJcTittwoZFBpkjStCWFcUKVIVPhSao5C1F9LpeVtPIc9AoTGqIp34gykNhfiQUmCdIyLxT2goxHGGAEFWlMGrU++FCCoI8HRZI/5fSoUI7akuQrkMk8eF9hgULv0VvD+RIDuDHKlpeoViBHDSHKmhV7ag8JajqGFS3FTgypd4EQUfSH5fOACFRsg7IhYrIq7I9QgdTkOhEWoUAYLflbAeX/CrUGhqvEw8A0kr2PxvoNAEARMKPBndhR4EItBtD4Xy6k89i1sy4yGylwrJNwryHQlj+2E0p1Ep6h1MGBgOQKEJAq7zQUwUVfAJKDRB0Ut2LGmzhXoPhUITrLeFEh7RZHbeJnKagcLn7WRNZtMeWu2lQvotSn1J9lC+BwpNkMsKDYaiUmw0tkIoLHgJCyjUm+HIGBQSOJDGHEmLHoGoEAplNWGC8KCXRI4bCmttoQE/FZmZo1C9BoUX9BROaH6Dzb81AoXPCC3+iRIwjvOoVEg0spfsjK5dJHBLAYUHRHKF+SyBwU9Q2Ca02KX3MJdkaAwKDVFVSTVhwV+m0/GhUL0Mh6hV4kNhsxSgsxtaxMN6rEJJjSMi8Enn1nCcUTd485Fl1BkKhfnJcGDp3EdfAOJCyRp/vkP3A6MCkJ0RosLxvp/4JdEhd7rNCkCONGmaW7Jh0pEGmWmDULg+8WWT5LH3rVmJzL2537AAKJyxE1/5SnKbT1qu47ru1CW6eTUUXsQTPLnv4faVz20kLADlT1SBwoDrFSHSBaXAvct9cgUUVulF9nSBwgt6bTF0gcLb3jLvmYfCgkf7QAqFaiYTNWpX07mWh8K2BSe51+7rPHnjz/aXiAiAwlp7YY+B5l7Iui5jzB05TiObBoUFRyhgc7fC4JA7u3ty9yaN23kM8OpdSGCfe2iOcWuUhEMo3GYv4EXeQ07JT8MUzqpQOO3pD7M858z7bRcBAVCYU4QVfXFvylgXpQAoJFB8oerWbQstWD5K4FgKhUVHMfUg7o/+NSkACkkOlfUnFP/z6qBw6Zl2tObJFh1inYRQKKkquwz9a8qO4GEoJEDR0dgJc1lyV1FQKDngiUisE+qntng/FJpGv1+Xz/1I1tskJyNAoUy7hOEjGZ0MgJWBQgq8E+HQvRIqGiZbWgOF8gpC4nZrTpkZgEIS5Med2Gft24hWCkOhJP+1a0stvtOtPT6YN0AhDXJvZ517Ejm3Rt4tFRBcpztvDQolZ1f9ZLl3YFOXNi6gWJFfhUI6rN3S8eXlFa9/tLCL4dNQuAyY8YjNcIbCXLXSmv409WYoNE1uc+eHf7Q/u2hFUkNQaJhgtc9szqYeWIDCehHD3hQUGiU4ytJ3aWLdi1S33zoGhUZ540x6Fvbe4rSSttZBoUnOeen/aM0syiq0odAkwWRasr05VfkqhELDfN6SnkNj16LshVBokvF0CbtTy+w4A4XTZ0oVNl5chActRhEXGmRbeh6Di/B2+m4oNEjPfIWNmcpHJvZBoTkKLfMVNr1SeZq7HwrNUSMVygNNxSMTd0ChOTalQzRmKp1P43dBoTkOhxU2TegIyBEpvIDCnnSYXZWmZ1gdFBqjINJhWlN6UQWJ60IoPJNOuhne9igcSKFwuiUdpumUjoC8TeG5SSi8FaUw/bJecrWswgYoNMe6v6MUNlc2fBbNaSapjVQ4XNF7CHwPFP5vBNV6Cqf07op6DbcXQmGwZcWKlftL7dSmo9iuF9ed94zmuKEwv+pyR0dHZ3uJnprIVdiodx7JM8V0qMUFCv9l72xDmorCOP6kei+yABWwj+qMgIhcEQQaBuBAgkTQJRfrckwaiZAXBW84IgIsIiOALC7BUAkSAyaJGyB9iqAgpKAI6GMbRIS4CREDKO9ePC+7dzttniQ4f5wOjkN2f/yfl/uc4zoN1ZYnSjL85YjQP17G2Ff0Jy9LhFsxI6tQNFKqqfBz3uPc1hwyoahb3BLhGKg5eSaJqvKhI8KbnADOhAtNGJEIBY12V0w1r9DwXiFM32VDqSVqSCERHjJVrJVdp6R6y0KIXcyEUu2VKAASYScYWJ5pPGziyoWNQWTGgh0OAJYsnSTYVzqM+gCBAtlvEYmQX2MqIVhpxiPf0giTpz8mrIA2F7/t0C9e1TBDbYijoayzsM5KhNxKq5Q8u9mwq3RTkToY0LMLgW/DhUha3uaMqM29b/+7PcQBiZBfadOgGEbx9qdSrX26JozZXnRg2HQjkfng3p5qvml/WUcvJMKUydiwvVhJGifdVGNbEDN0Mk4bCsWUEc7ENlre/6eRCGMMwny2S79m8LHbEJfCdIwdqvTmy+ieuFC6EFbzK7UOCAeJftLPBtlK24a6Ml0oc6FKy9gdNziMm/oxgGsFuTIwvh8ulAiTqkGrWDLs/YBNqBeuuu9RFJ8LZV+I5dn10kyxHWzHHQpWP8eFlxVpRVr0eguLw9MGLfNAfuVYQSTFBzyTTsWOv1+oCyXC5BEACBZU+M9VRhPuW0kfMedHWV1qFpkLJcIWyEg5wdyPXmEQruLIxrrsAZ7pdpczTpQVaUVKgbIjQKB0FG0M1Sge+zJWS2BvrHU76pxAF0qE9QpkCCIA2odjBq0pwhdxl4ozNeCM8LHAXCgR+gAhQBmKQGWaZwzCKF7a0ikTjrsMhLHiEWEVqUSYREgBpGQfCll2bMfYXIh1ikDlv+C+yxR3HcJcKBGmAWyGkGVYRUVSd4TpNRwxB4jLetgFof/Wv8iF0oUACMhcU2+yTQXW9ic9lwi1aQLAlW4XfRdYkUqEQERSVN1MWC0EBpZJNwZNM2Hbcf7w6m8ehF/FuVCWM1kXAuR+kElrnsyGHsYAjZ4NXdd7qigAtW4I+8TlQomwBbvQ/lJIh3ro3TOMFoNBfOCCafpZDYqrSCXCeZKgolDZ8Oc6ZvjCGQAnwiFxLpQItzPw8nFUgWrKovlQCiGui1crBGHlLmxYXvR6jy5wl+n2r3uX/58bbARDBRRqq2bSFzMyCk24AuAqZ57sY0W6iEKzmwHNCr+5M3WS50ieen8zoVnWjy/GSIT/r7S1eRf2aVLhoyIpwDD1fnzrdmthn4zhUZeIXMi6EFuroYFjDnN9w7ICCfvVAcsKf75cfGrSiGY1a07X7ai98+T8ZCsPg0bfy42dV7y7N9K6Hwjrc/RyZkRVzCVApmmMcAawp3EXhJUM7v/wdj6gcRRRGM8fEk0ExBQMBGTDBrWkxVaCJRbsAggQBRBxMIO6NBQvtQoHkRYCyIFWkgChQZ3okNxBEggShFMEVJGWCqQcGKGFRE+SIOgKK2XpJVDkgqxs7pLdmTdvCdyMbwkBbu4I99vvey8zO29UuXDnzEPfTm+u/fpNJt1aH/2BchLE4XH2y9MpwE+XOHMTwykfbrUkT17pqV8HL1RHy4yTKDgfftf6/xFWm5IMpVm2COKifeRb6x8M4R9aK9Lq6DblvPadrbVaKQ5TYoEcdL4FTSrvcVce7rMNwYFO/rRZv37O1auJ5Jl/Ht8omkRYWVlcgd7TmyAYzdU0ULhj09zPv6BThcvXKXEPifBbqKwGIyIgCPtaPfzYFFON568mlf44J3T/IvxajWCZicN/L5pDWLGj6LdAQRP7aPTjNFAbYXOkOY258ElflBbNX8IIBurgY0rTLRXASLh35ylX3GC+MyW/i/5lGUPYZdcYFlEZ7v9qZFVhHFmpcPRVpN1Uloo/36xCcoK7CEKPjcDhu2W0wRhdxRG2Qe70R2MI7YMoojKMVNipoXE3eHhGmwrvlyAYL+8oyjQaoOHNgzdUxgv4ePo+hvBzFsBgWeMIbQvKMFZip4b+XqAg1ZYLO1Ra8T+1gKeX3QAPfxbZQo5EIatGuFtSqnzWMELIsHpelwqrnjIV3tb2HOkeUyO5A5prpCIJ6FdSIUZSh3szaoTn1OCpYx5hvzS10JRgOBI2EM+oChrP0aRC1xkXtIV7130JNfReUbcdbvp4ekOFcKeEEP/IEMJF28bS4VKCoaO92eVsqAlhsCyQAd4FkODh/yZ0FpCIw5izFAi/wKSeLxqrSNF0+MQhwwb3s3dAGQ7ldO1seuMdlAx9WLiTABIQeQvps4nKECKcQnNtzgzCnQRBecal0nfAsEV7z9k5S5cK/1wXKOAyfAsXYUwAIY7EDESIn9vgfWzsX3tchqF9uvZUd6NNJd6UGQ7dCLUZqUAG76e4C5HgzCFxpEQBCP/FS6bPtCOEyRBOfPb0ZTLtF/ob7jlEpL1pL+naIpoe3stIJ3ecSfwnH+Xz/5YQehuXUzTuaEcIndRWyHRxRUNLu+NEIPiJo22jdnrMx/uryhJdygkhlGEdwR+T1EQ4i4ZL0pyTEAa+m2bT+hFCJzXWhuc5kiTYHBpGCEuIeyISj619mRnIvL3NRSaHTjouyfP1ifaBM5lp6gLVCgjTPcEMwrALOKmRGCRunaD3SmcY6jdSwiml3AXJTemjfr61ps+uiyIUckqZOdnG2ZqWe9eFF/ybECEes0YQwoLGVPRepWT/9n/xUhjqUCGQyZXzD0z6BeQo0u8Esvl4MeoEBbIFZ7rRD+K0/mEBUDkqwtcMIQy7TDtpvKo+vbU1Ed3+2hF6bHUfSmX5OgcnP0FVCasSx5lodtCp/VVh9cIVki2CkHDOXXC0rX6EUIZmNyg8srAAZK7FSAtjh088XGSq/LNXwGdP25IE6nvmynh71G7ho7JKhB6/Ozk5XWISVscQwrAKkqHZ0K9C+r24vgCRPIu0jQYKJafAqXw0h0/UeTdVCOlwJvoilx6ULCGrHyG00v7/2Lu60DiqKByQdq1BYiiUEiujQOKT3dZQCgXdV5+NI13cDn2x0KQyq0GXGqBUsRjAJBin6ZB0IO2LQGEXhcRYEapoTfClFJE8FSxXGCklOwtp2CLRjc3eOfebueO418DuzGGfMicDzMd3fu6555x2hNAl7Rl14vaMMgSY7nnJ21wTSDvLNTG4nQ6A0G1ey3jJAUerBEKUK+3EQjSkl7P0E1vEGcKixDkNMBEzw35Dls6NE3wBQjZbBsbCm1RDWL3SzixEVhkUElr6Y7/5VDHtH+K+FhHH3RpGFiC0TNiGA/RXBiFimG1DCGdxi5C4RO+BI/VIRwzBeY6TF8je75oihC6/JiNYcHZLPYSIodZ+htTFD3NWrCZc82EUcGlnzaEFJ8+QW78l+phCWCA0OOCDm62ohBAx7GuAOL/ZfizEUB0R65efkdSZD5MsD0jhcBpZy1YECNkQMFYlhHLp7dU22xDCqU25pctSfXYjiNV6U/ImZ2VYieihxfWnCYRgp+s/gBeOAWEHy56IdaO/CJ90KWJT97Wfm9K4U/+nD5Og1o/aPa7/O4EQIV8KXNWfQniaQoTPBV+2SliJUp2f7+t99CsTQ8wCpzr0NbX75gUIh9BgyEsVKYQFTb6c1L1DrRnqo7xsxMjlKITuJPhNOQtTQ4qusJlEcAfkMZI0RMqbhOTxIDQxtJKzMGXhdPB+WaJQM0hAGstO52JBiNWI/U4ghCmEJMBEqTGCGUeUxPwomFfq8SDEc4YNR2ZIU0OKvgpD+akGhPEC+yVglRxCGckfdiYL+wYHj6mZCow5AtT7ZiiEK/EgvKzFg/BTcMsdASHOjyiVSrsPtwahPNz4iJi2NQfSSKmMx7v8eVCWgzzoQEPqnbxeypQyY5WsCkPKzCgeHdf8ELJbcVgYH8LzeP7acaczXqYxtyaT6costMRCOYTvkkPSFlg4Gw9CdM1rHWdI6yMNALdkzFQEoTxxLFAW3vhfWeie63wWPrtY3JbMlyoiUjMqLXitvJMQ9nR8OFNb7Mo0ZSyrPpxBCO+VISLdURZ2GoQjxZJv55OpAMJzUd6sQCH8TnlSIWfhWodFpOuVYjHD5X31qT1Wm05oBMK78U5nCmUFhrRjfCEuuhhVwMI70tMZhHAoXjlSz8aEsMMNaa0I22ZagFAS5dUYyQtruqJj7jSceb5E15AutG5IoysVs1hsQsgHueSii01Vn/qLyfKFIyILtRZZiPVCbKGYonb1eGCJ2LLy+j8/uzE6xpCHS56tb+vnZ5LAQlw2gyxUX7XnlpO2+LIg53ZEZ8ajX97k/x6WR65b2/qMTSeKhWtFQRZUDXZGiKnzG4+wjGfp3ZoDBtcfkpOc/ZEoFh4V9zm/p4CF7mRgoYJ+t10+yEG/wVKaRWyQ293y0sRkolg40lWk8kWLEGI8g+Mq2C16GYbdjYp+6GcvlOV3IHsSxEJcqp55ogVDCkVZNHQ89++/L6EVZd1Fob0wb0qzTj2XJBZ6Fc4/NQds6NzwMTOFngqWQ31hlIynkz/IWzCSxMKaCGELx9w4GAtZwhGjnU3nZfpsEjsIReknrjJJLFzHgLRFQ4qbKnDszwlNcHZoSfdD69oeGcvry8QTJ4mF6xWIZtS0iAr1oyrp1J4CXgImS9BrfwRblbh87kCvfVJZ2G0q6rWfyyGpOACAEhM6XZ62wGw+Y4R3v9VXCUUTzcJKWVGvvUsw8VbJs0mceJF/m0AyDohTw8voGd4LDjHiiWJhrZIh8o66oSUfcIUqXTHgmgFT8eb8/D/j3IfE39PJO2771PfZMBMlISzEpGIsp276E1/2Uj9jkScFDWl1n10abuq/ZcNcPJiiZ33YzD0H6EKFV5NVta/COm51Y/SsC1vjVnoHvrVwdB2PIvlSioXnGqj0DUxQ/UvB00vtm8O9DYZffdw1YJJMQliINfuSqXKMHrNPVHafykzoYQNGT4v6hY8Xu76asAX9af7hidj6T9eL3Z8wm0KrZxN2d+Ypfzg6qngeKbP/Fj10Eu+GI+rrtm3pOPWVs5aKHvT6qaRV7T1fvbBSVtQiKpcZGLQmFb0MPAcBjieqan+0GZMu5nZmKvBKvH+5COSRip5N3N0Zr7u0Va0vLQ7v0GDnHFQvQIJnHlaXo9XZxQTeI93X3bCl1yvD6nrt80b0N0bvFr2G4GA05G5PEi/kXz05NlY8dVhho/boWQmremD4HUpIDSN6ywGbTcJtbpT6FT4lTAmE5oYj220Wh4aXNfmeNQxfFbAw7bVnZn1VSkI83AxVp4VEz40g4Yyanop04oUZaiHd18UilBEJCRfcBorbhBSxMIXQW/6Xm13X8zIEHah97XJkCH6vqrMpNaRhdLFJSQn2GYD616AOm7HJ/G2tpZ6KlIVk9mQ1aJlv/vYmyhnLCEMwSH3vsh7GwUtZRf2FKQt1E9Z/SDbJV/l+HyLMvhCcx45bwQi+kUtWZ5N6udrsKxosb31qYauHbv8YcgZ7aBmJyPJOWOWr9o2tg7pu3+QIpixUJPsm/GWg/NyoFqa590nXNijcn/16LDyPPTRhE9BZ3nrlMe0/9hf+1d75uDZxhnE8rayu26BYQaAbxEYcLIgVAxllYNg/MES94rFxRItREbcxmN0cINvosAhYHBf70jagBR1FmyFMkax0k1XsVtkcuNmh2xAOrNNjl4BAYGTvr95zr+muKux4ffN+CSV3SQrw4Xm/7/ve8z6PRhii8r5pZDJ3NO1fQ7d/Tj07bWORr2Kh+0ts95Wzk/PINMk/x79ChfquU+ttsOZDdQgDHx7TCEPVnp28OYt15d0l67udzPVN3sJfvXWj1JJaerPIG0vvLt26OXv1xpEve5Pxx6x48dbsgr67pBEupY5xLOAXKm/F+IrH++f/2TJsZQpUrOM/DjqhAEItlRBWE2s2Jp9eABqh93I2hpXrfEoBaIReOsbU0vV0AtAIMcEsVawlLgsAmH0Un9AakslEkb4hkyrFEZ4iBFti5BXbIdnBj0JIscRw/W077Ln/OgvvvquNsEoIxjhDycLwge08McICz0qcKFhmRm2Eq1taYvjFGMYyykQh/mmDRKEXo+gW4nCHcggnMEK1o7CCwWFxgtlmZRBaru+FhtpRuJrMYuhQShk2qxSF1xojCjcQdDgQ+ax0mXpeWFA8Cj0+gCo4kHKEa5GNlEZYpeTgz3PqRCH3wlW5XK6oNEJGLptlDBVaVFhCLxqlB1IGMMZnpV2qeaH6CGvUBf0NmmU15bxQfYSrCTksFoRNNeW8UH2ED9iElG+yhfi+9kJZVcUE2bIw5EGF9kKptSrGGGKCzUVJEXprcqniIu1Pc72d9QDKqWSoF3ak06m4Ugirq8nCnkQhTsmUE+HKrw3DuPNQyq+X/d2xDCvQO3MsndpJ8pAt63wRvHBlbzpN8ad60xn8s1evO7Z1p1kNhMCQamdXTU6ElRnbcR0H/SIYwAvIshzXQkN+pnE3QoO18hzGjv4s+l74CkJ0d8abQQjXdNtPssctw/5UrdyZRCqXI1m1ciL0LvIsevRzIAbfRnXHmtYXnHxtgn4ZtfleiG+YFOEcOcz9Bf+Zg5oUS0JcQfJi5UT441nb5QrsdZ5FkLOdhzzuHn6G38j4XriOP6nw+jHCCpz3HirqVOCIEP42R44v2QaDxYVR0Lu2xQvUcIR5fu5lCLxwgj4v5AjX4o+xr9LoPRoNQo3QvYpZWEdK03bwRP0mQsq+UpqcIW+GfYRbuy1eOIp7oRiFB2cwum2zb9AQHowIoUZouM4IPu3U/lUBKnOXDVr2FLv32IBFi2lwhJv7XQch27rL14ViFDqHCy76aeOJsf1kbLaKkSDUCLHMHX6J6NG4X1bYPMeG1BlaV4ojvGe5IwfSe/CRJsELOULXwDWF4+T9LoucPowEoUYITYFeLPiVoVtpJSKo3z5S5Agd1zxIKjFkRC9kAymthRL3u2LO/xENQo0Qur8OLHS/K9uBGPIG2AU/WZgX90jFKISWCjgMnS3RINQIORTeKCi/cNz6eC1w2/meIQSygheaPArpr6Co7efRINQIoUt3BV+NslrdLBzhdp4hhNZqi3shtHx6gHEPRoRQI4RckAE+qrZyU4SRdJQhhDATvHCeRSGc3GYNhTdHg1AjHILLXQydN8eZQQExI8MRbq2FeSEklHrTkSHUCPO1gOvRfjPlYLRRdLzVDzdF8EIxCoUOlv1RDaQaoXNbaE7pvE7uik19/ylgw+Qop2phXrhd6E77pkYYceIFZ8cC7G5NJHuNI2wL9cLjQs/n7dEg1AinasLcswdHncXBQsC5d2FADfHCwNDZGhFCjRCgwPLhJQzlcg60DyM8xhAa74R6YV6IwjuRI9QIqw4eC9kSfx6BbN7wfj2BFeKFAsL3VfRCbzyRSJ6QEyEs5oYpKlGA0MiEemGP2gNpR4IqKRvCjBiFw35jWEE9DOG2rlAvzCs9nakmuDrlRehdpwg3LRKFeYbQ6npUL2xVzgu9hK+41FHIEZo2El6A8BG98EPlvLAdEHZKi7DsI3Q+y4lqBoQhXphX2Au9REBxmWekg7CEF8QRNq4XtgcRFiVfF55ZLNe+4b3wZBBhl1QID4kIt8LujKBG90IvIS/CKeHS2UL3RN3bdQAb3Aur8iKEeCPs8CWhw2GAtBeWBYSdUiHcIj4vnCJ3ycQUVOkd115YTsg6nREyXPayhIuqJebxnkH3DjfJ64Ua4VCtLneGpR0CWctAU9oLg5I1/alCgPJodG4LDUnNTKN7oSefFQLCa8E80p6FN0NCH6aReMOvC6WzQkDoDgfTto/y24H1YrdL2DS2F4q7M0nZsrnNNjg8YWb40Al5MOVplqev90h9FWVD6A7HKao54NZNUu8/gaOGZkbvkUIYdsp3vtAk7Q+rzxBf/Bjsz0XvYbTeazZ+O6jXhcBQusQLZ7Lgmn+1LO8nqAoLPk3bcaMfDuyeRC51SO2FWB0nSeqMfOlPKczOZDlO85egD6GLhdhtZygu9R6pzmBjx+cpKvDpvQXXl3lI7j1SjbBiWvWlYspzPkPzssTPCzVChFBb7bRJcJn2uSDdynVEyRromzhUf0IZf6jFF98+XP0pgPAiQqP/P0KtypG+EoayYRpjuN/80GcfzCPbRPfO+3kipy/0XSj69Et9pSZ+t0TBPt/3UaBV956+vvPRIdRqT+d662daY+nluBSi6s3vtDRCLY1QI9TSCLU0Qi2NUCPU0gi1NEKtfwHwtKaZIWZ0EwAAAABJRU5ErkJggg==\">\n",
    "</div>\n",
    " \n",
    "<h1 id=\"course-title-heading\">\n",
    "    <div style=\"text-align: right\">\n",
    "        Models of Higher Brain Functions\n",
    "        <br>Computer Course\n",
    "        <br>\n",
    "    </div>\n",
    "</h1>\n",
    "    \n",
    "---\n",
    "<div style=\"text-align: left; float: left\">\n",
    "    Lecturer: Prof. Dr. Henning Sprekeler\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: right\">\n",
    "    Assistant: Jarek Liesen\n",
    "    <br>(jarek@bccn-berlin.de)\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General exercise instructions\n",
    "These exercises should be completed entirely in this Jupyter Notebook (comprising source code, discussion and interpretation). Submission should be done through the Moodle interface and should consist only of this notebook (**a single `.ipynb` file**). This Jupyter Notebook was provided inside a `.zip` file, alongside additional files. Do not change the relative paths of these files when working on the assignment (meaning that e.g. `./helper.py` should always be in the same directory as this notebook).\n",
    "\n",
    "Submission deadline is the start of the next lectue (**10:15 am on Fridays**).\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Some of the exercises will be automatically graded. Make sure that you:\n",
    "1. Fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\"\n",
    "2. Remove all `raise NotImplementedError` lines once you inserted your solution\n",
    "3. Don't use variable names starting with underscore (e.g. `_myvar`) in your code, which could interfere with the automatic grading system.\n",
    "\n",
    "Before you start, please fill in below your names and the name of your group as shown on Moodle. Example:\n",
    "```\n",
    "NAMES = [\"Martina Musterfrau\", \"John Smith\"]\n",
    "GROUP = \"A\"\n",
    "```\n",
    "\n",
    "If you have any questions about the exercises, please ask them **on the Moodle forum** of the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMES = [\"\", \"\"]\n",
    "GROUP = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are a few tests to make sure that your installed Python software is not too old\n",
    "import sys\n",
    "assert sys.version_info.major >= 3, \"Your Python version is too old, please update it.\"\n",
    "\n",
    "import IPython\n",
    "assert IPython.version_info[0] >= 3, \"Your IPython version is too old, please update it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a85d0ffcfd46484d81435c45ed59068",
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Week 8: Reinforcement Learning II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51be812f836b655fda1468be146c264c",
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Necessary imports for this exercise, you can't modify these\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import functions defined in the ./helpers.py file\n",
    "from helpers import assert_var_defined, display_animation\n",
    "\n",
    "# Import the GridWorld class\n",
    "from gridworld import Gridworld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40663a7dc7a6d69b0a7766ac53089319",
     "grade": false,
     "grade_id": "1-intro",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1: Good vs. bad Döner (7 points)\n",
    "\n",
    "Consider a hungry reinforcement learning agent standing in a street with a bad and a good Döner shop, which are at different ends of the street. The goal of this exercise is to study the effects of the discount factor on the behavior of the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d70d0b3499d5f41f2fd6efa65d4435f2",
     "grade": false,
     "grade_id": "1-1-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.1 Implemente a linear Döner-world (3 points)\n",
    "\n",
    "Write a program that implements an agent in an environment of 50 linearly arranged states (corresponding to different positions along the street). In each state, the agent can choose among 2 actions: up or down, which take it to the respective neighboring states. In every trial, it starts in a random position. If the agent walks up in the top-most state, it receives a reward of 100 (bad Döner). If it walks down in the bottom-most state, it gets a reward of 1000 (good Döner). For every step that does not lead to a reward, the agent gets a negative reward of −10 (still no Döner). If either of the Döners is received, the trial ends and the agent starts a new trial at a new random position. Initialize the Q-values with small random numbers and let the agent learn according to the SARSA algorithm:\n",
    "\n",
    "$$\n",
    "\\Delta Q(s_{t},a_{t}) = \\eta (r_{t}+ \\gamma Q(s_{t+1},a_{t+1}) - Q(s_{t},a_{t})) \\, ,\n",
    "$$\n",
    "\n",
    "with $\\eta$ = 0.1. The agent should follow an $\\epsilon$-greedy policy with $\\epsilon$ = 0.1. At the end of each trial, store the mean of all Q-values and the number of steps of the agent.\n",
    "\n",
    "*Hint: Terminal states in this setting require special attention. To ensure that the TD-error can go to zero in the last iteration, you can introduce two additional states at the borders of the environment whose Q-values are always 0.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad08ddacc3a5ba1360e6a86f02da1f63",
     "grade": true,
     "grade_id": "1-1-answer",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9140e343bdfddede15095bca89f9edad",
     "grade": false,
     "grade_id": "1-2-a-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 Implement the agent\n",
    "\n",
    "#### 1.2 a) Simulate the first agent (0.5 points)\n",
    "\n",
    "Start with $\\gamma$ = 1. Let the agent learn for 50,000 trials to make sure that the Q-values have converged. Then plot the following:\n",
    "1. The duration of the trials as a function of trial number. This shows you if the agent is learning.\n",
    "2. The mean of all Q-values as a function of trial number. This gives you an estimate of when the Q-values have converged.\n",
    "\n",
    "Generate the same plot again but this time zoom in into the first 500 trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "14be84dd6d3a969e747527b019e04acb",
     "grade": true,
     "grade_id": "1-2-a-answer",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "216156644048600d72747f347e68f82b",
     "grade": false,
     "grade_id": "1-2-b-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.2 b) Explain your results (0.5 points)\n",
    "\n",
    "You will observe that the agent’s behavior improves a lot faster than the Q-values converge - explain why! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eeb9af761d0d6de9fb53f471ec0a6fce",
     "grade": true,
     "grade_id": "1-2-b-answer",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "999b13c74fdac16a9a21e2d283480d16",
     "grade": false,
     "grade_id": "1-2-c-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.2 c) Plot the converged Q-values (1 point)\n",
    "\n",
    "1. Plot two curves showing the final Q-values (after the 50.000 learning trials) over states - one curve for walking up and one for walking down.\n",
    "2. In another figure, show the preferred action as a function of the state (up → 1, down → -1). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c0a063616f182df8930b6c01cced3fc",
     "grade": true,
     "grade_id": "1-2-c-asnwer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bbf5955e6d2de9aee55ad986649f39c9",
     "grade": false,
     "grade_id": "1-2-d-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.2 d) Explain your results (0.5 points)\n",
    "\n",
    "How does the agent behave after learning and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8deda85d655d90d1bd05a6a1940d8a45",
     "grade": true,
     "grade_id": "1-2-d-answer",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c3ea9d9fcfaf3af5cd1d6a4e1402783c",
     "grade": false,
     "grade_id": "1-3-a-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3 Repeat the simulation with different $\\gamma$\n",
    "\n",
    "#### 1.3 Run the simulations (0.5 points)\n",
    "Plot the converged Q-values and preferred actions (as in exercise 1.2 c)) for discount factors $\\gamma$ = 0.99, 0.95, 0.9, 0.8.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1ed67e9b5df9c6b03be193eeb650a5c",
     "grade": true,
     "grade_id": "1-3-a-answer",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cdcf546787e82720143e3158c60c593b",
     "grade": false,
     "grade_id": "1-3-b-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.3 b) Discuss your results (1 point)\n",
    "\n",
    "How do the Q-values change? How does the final behavior of agent change? Provide an explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e05776a56d7f1f51245d23be27fce4a",
     "grade": true,
     "grade_id": "1-3-b-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9def3abaea184cee28c14256dc454153",
     "grade": false,
     "grade_id": "2-intro",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2: Gridworld (13 point)\n",
    "\n",
    "\n",
    "In this exercise you will implement several methods in the class `Gridworld` (defined in `gridworld.py`) for reinforcement learning in 2-dimensions. Most of the class is already complete, but you must now apply your knowledge of 1-dimensional SARSA to a 2-dimensional problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb75d0ed7a2c12f5ea1510a975f3f597",
     "grade": false,
     "grade_id": "2-0-intro",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.0 Animating a trial of an agent\n",
    "\n",
    "In the following, you will let your agents learn in gridworlds that you define. For visualiztion of the agent's behavior, you can use the `display_animation` function provided in `helpers.py`. This section will show you how an animation should look like once you have solved the exercises below.\n",
    "\n",
    "Below is an example that should show you a running animation. Here, the `_run_trial` method of the `Gridworld` class was implemented such that the agent walks from the top left corner to the bottom left corner. After executing the cell below, you should see an animation in your Notebook. If this does not work for you, please contact your teaching assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8b946c94fccc141075699ac0a966831",
     "grade": false,
     "grade_id": "cell-1b6264ad87e4158c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def _run_from_top_left_to_bottom_left(self):\n",
    "    \"\"\"\n",
    "    Run a single trial on the gridworld where the agent starts at the top left\n",
    "    corner and walkds to the bottom left corner.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the agent at the top left corner\n",
    "    self.x_position = 4\n",
    "    self.y_position = 0\n",
    "    # visualize the first state in the animation\n",
    "    self._visualize_current_state()\n",
    "\n",
    "    # Now do 4 steps downwards\n",
    "    for _ in range(4):\n",
    "        # action = 1 means moving downwards (see Gridworld._update_state())\n",
    "        self.action = 1\n",
    "        # apply the action aka move the agent\n",
    "        self._update_state()\n",
    "        # visualize the new state in the animation\n",
    "        self._visualize_current_state()\n",
    "\n",
    "    # The _run_trial function needs to return the latency. Here the agent needs\n",
    "    # 4 steps to reach the target.\n",
    "    latency = 4\n",
    "    return latency\n",
    "\n",
    "\n",
    "# Overwrite the Gridworld._run_trial method with the function defined here\n",
    "Gridworld._run_trial = _run_from_top_left_to_bottom_left\n",
    "\n",
    "\n",
    "# Define a gridworld and display an animated trial\n",
    "g_test = Gridworld(5)\n",
    "g_test.run(N_trials=20)\n",
    "anim = g_test.visualize_trial()\n",
    "display_animation(anim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "166c246c32108133fe5c1ba24716f5ef",
     "grade": false,
     "grade_id": "2-1-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.1 Complete the `Gridworld` class (3 points)\n",
    "\n",
    "Now that you know how these animations should look like, review the existing code that defines the `Gridworld` class (defined in `gridworld.py`) to get a sense of how the class functions. You can execute\n",
    "\n",
    "```python\n",
    "Gridworld?\n",
    "```\n",
    "\n",
    "in a notebook cell to have the class docstring and initializer docstring displayed (which is defined in `gridworld.py`). This gives you an overview of the class attributes and methods available to you.\n",
    "\n",
    "Provide an implementation for the empty methods `_run_trial`, `_update_Q`, and `_choose_action`. To do that, complete the functions below. At the bottom of the cell, the class methods will be overwritten with your new definitions. Do not modify `gridworld.py` itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gridworld?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33353c4356b554b182c2e948a15e9f30",
     "grade": true,
     "grade_id": "2-1-answer",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def _run_trial(self):\n",
    "    \"\"\"\n",
    "    Run a single trial on the gridworld until the agent reaches the reward position.\n",
    "    Return the time it takes to get there.\n",
    "    \"\"\"\n",
    "    # Initialize the latency (time to reach the target) for this trial\n",
    "    latency = 0.0\n",
    "\n",
    "    # Choose a random initial position and make sure that it is not in the wall.\n",
    "    # Needed here:\n",
    "    # self.x_position, self.y_position, self._is_wall()\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # Run the trial by choosing an action and repeatedly applying SARSA\n",
    "    # until the reward has been reached.\n",
    "    # Needed here:\n",
    "    # self._choose_action(), self._arrived(),  self._update_state(), self._update_Q()\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return latency\n",
    "\n",
    "\n",
    "def _update_Q(self):\n",
    "    \"\"\"\n",
    "    Update the current estimate of the Q-values according to SARSA.\n",
    "    \"\"\"\n",
    "    # update the eligibility trace\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # update the Q-values:\n",
    "    #\n",
    "    #     deltaQ = eta * e * [reward - (Q_old - gamma * Q)]\n",
    "    #\n",
    "    # Needed here:\n",
    "    # self.eta, self.e, self.gamma, self._reward,\n",
    "    # self.action, self.x_position, self.y_position\n",
    "    # self.action_old, self.x_position_old, self.y_position_old\n",
    "    #\n",
    "    # You need to make sure that your position and action variables are not `None` (which\n",
    "    # they are initialized as).\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "def _choose_action(self):\n",
    "    \"\"\"\n",
    "    Choose the next action based on the current estimate of the Q-values.\n",
    "    The parameter epsilon determines, how often agent chooses the action \n",
    "    with the highest Q-value (probability 1-epsilon). In the rest of the cases\n",
    "    a random action is chosen.\n",
    "    \"\"\"\n",
    "    # Be sure to store the old action before choosing a new one.\n",
    "    # Needed here:\n",
    "    # self.action, self.action_old, self.epsilon, self.Q, self.x_position, self.y_position\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "# This overwrites the class methods with the functions you defined above\n",
    "# Note: You are overwriting the methods in the class definition. Therefore, in each class\n",
    "#       instance you create below - using gridworld.Gridworld(...) - these new functions\n",
    "#       will be used\n",
    "Gridworld._run_trial = _run_trial\n",
    "Gridworld._update_Q = _update_Q\n",
    "Gridworld._choose_action = _choose_action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bbba1b937b77d6c3c0cfbae5da7b4d62",
     "grade": false,
     "grade_id": "2-2-intro",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.2 Test your gridworld\n",
    "\n",
    "The cell below creates a gridworld of size 5x5 and lets the agent learn for 20 trials. It then visualizes a new trial in an animation. This is only going to show an animation once you have implemented the methods in 2.1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13e2cd0ee7fae6725c605d081286c9f3",
     "grade": false,
     "grade_id": "2-2-provided",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# The animation will only show something once you have implemented the methods in 2.1.\n",
    "g1 = Gridworld(5)\n",
    "g1.run(N_trials=20)\n",
    "anim = g1.visualize_trial()\n",
    "display_animation(anim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "91a9f8870338f001d4e7f318f64a6eab",
     "grade": false,
     "grade_id": "2-2-a-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2.2 a) Create a 10x10 gridworld (1 point)\n",
    "\n",
    "Define a new `Gridworld` of size 10x10 and let the agent learn again for 20 trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c2a965f5bf50fdd4d377137bde3ef66",
     "grade": true,
     "grade_id": "2-2-a-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d18452362eb9191fb144b0a6910eb69",
     "grade": false,
     "grade_id": "2-2-b-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2.2 b) Compare the two gridworlds (1 point)\n",
    "What is the qualitative difference in the trials of the two gridworlds and how would you explain it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9b3a04f7319476c9d6c290275e8a546",
     "grade": true,
     "grade_id": "2-2-b-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57d5e28f50724172ed6ca525a7570515",
     "grade": false,
     "grade_id": "2-3-a-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.3 Compare the navigation maps and the Q maps\n",
    "\n",
    "#### 2.3 a) Plot the navigation and Q maps (1 point)\n",
    "Look at the navigation map of the agents, i.e., the action with the highest Q-value as a function of position using the class method `navigation_map()`. And also view the Q maps individually with class method `plot_Q()`. Do this for both gridworlds that you simulated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "506dc0ada14e2a18e1555635e4efb4eb",
     "grade": true,
     "grade_id": "2-3-a-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "918af478793d8822b95b101af484a3ff",
     "grade": false,
     "grade_id": "2-3-b-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2.3 b) Explain the agent's behavior (1 point)\n",
    "\n",
    "How is the behavior of the agent reflected in the navigation maps? Compare the structure of the maps close to the target position and at larger distances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e76eee5d71cefd4e25b643b828d90487",
     "grade": true,
     "grade_id": "2-3-b-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a2884c12274a708b76fde7995fc018a",
     "grade": false,
     "grade_id": "2-4-a-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.4 Study the learning curves for both agents\n",
    "\n",
    "#### 2.4 a) Plot the learning curves (0.5 points)\n",
    "\n",
    "Quantify this difference by plotting the latencies (i.e., the time it takes the agent to reach the target position) as a function of trial number. This curve is often called the \"learning curve\". You can use the class method `learning_curve`. To get smoother curves, let the agent take 20 runs on the same problem and plot the latency curve averaged over all runs (rerun the `run` method and pass the number of runs as parameter `N_runs`). Do this for both gridworlds that you defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8923b2515596db7360c680330c489c5d",
     "grade": true,
     "grade_id": "2-4-a-answer",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49fa8da4a608b9a4e96c51a8f3ef2881",
     "grade": false,
     "grade_id": "2-4-b-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2.4 b) Compare the learning curves (1.5 points)\n",
    "\n",
    "1. Compare the latencies for the 2 gridworlds.\n",
    "2. What are the latencies that you would expect if the agent has discovered the optimal strategy?\n",
    "3. How do they compare to the latencies in the computer simulations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0391bcf79dfddb0bc720670952155df2",
     "grade": true,
     "grade_id": "2-4-b-asnwer",
     "locked": false,
     "points": 1.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9142cc0611e2f60e0dd5ab2253bbcf22",
     "grade": false,
     "grade_id": "2-5-a-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.5) Study the effect of an eligibility trace\n",
    "\n",
    "#### 2.5 a) Simulate an agent with eligibility trace (2 points)\n",
    "\n",
    "Create 2 different gridworlds of size 20x20, one of which learns with an eligibility trace and the other one without. To enable the eligibility trace, set the constructor parameter `lambda_eligibility=0.9`.\n",
    "Let the agents learn for 50-200 trials and 20 runs. Plot the Q maps and learning curves for both agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "154624a3637ccf8fad39b376595c454d",
     "grade": true,
     "grade_id": "2-5-a-answer",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3b94a02c7c73943745806231987ae91a",
     "grade": false,
     "grade_id": "2-5-b-task",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2.5 b) Compare the two agents (2 points)\n",
    "\n",
    "- Why is the runtime of these simulations rather high?\n",
    "- Compare the development of the latencies for the two agents. What do you observe and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d95e1f094554ee2dbc255b567487891d",
     "grade": true,
     "grade_id": "2-5-b-answer",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
